{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-12T03:13:12.434012Z",
     "iopub.status.busy": "2021-11-12T03:13:12.433285Z",
     "iopub.status.idle": "2021-11-12T03:13:18.239139Z",
     "shell.execute_reply": "2021-11-12T03:13:18.238196Z",
     "shell.execute_reply.started": "2021-11-12T03:13:12.433896Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This file is used for Hyperparameter Tuning of parameters used in the construction of the LSTM architecture.\n",
    "The parameters - \n",
    "1. Number of Epochs\n",
    "2. Batch Size\n",
    "3. Optimization Algorithm\n",
    "4. Learning Rate\n",
    "5. Network Weight Initialization\n",
    "6. Dropout Regularization\n",
    "are tuned using GridSearchCV.\n",
    "\n",
    "The remaining parameters, namely the embedding size, input and output dimensions were chosen based on trial and error of \n",
    "different parameter values. \n",
    "\n",
    "The outputs of the same are presented and discussed in the report.\n",
    "'''\n",
    "\n",
    "# Imports for Hyperparameter-Tuning\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Bidirectional, ConvLSTM2D, Flatten, Conv1D, Attention, Input\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow.keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:13:18.241691Z",
     "iopub.status.busy": "2021-11-12T03:13:18.241251Z",
     "iopub.status.idle": "2021-11-12T03:13:18.749690Z",
     "shell.execute_reply": "2021-11-12T03:13:18.748862Z",
     "shell.execute_reply.started": "2021-11-12T03:13:18.241638Z"
    }
   },
   "outputs": [],
   "source": [
    "tweetData = pd.read_csv('../data/Feature-Engineered.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:13:27.310280Z",
     "iopub.status.busy": "2021-11-12T03:13:27.309889Z",
     "iopub.status.idle": "2021-11-12T03:13:28.246913Z",
     "shell.execute_reply": "2021-11-12T03:13:28.245799Z",
     "shell.execute_reply.started": "2021-11-12T03:13:27.310244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Added in to avoid formatting error\n",
    "labels = np.array(tweetData['tweettype'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'sadness':\n",
    "        y.append(0)\n",
    "    elif labels[i] == 'neutral':\n",
    "        y.append(1)\n",
    "    elif labels[i] == 'joy':\n",
    "        y.append(2)\n",
    "    elif labels[i] == 'love':\n",
    "        y.append(3)\n",
    "    elif labels[i] == 'enthusiasm':\n",
    "        y.append(4)\n",
    "    elif labels[i] == 'anger':\n",
    "        y.append(5)\n",
    "    elif labels[i] == 'surprise':\n",
    "        y.append(6)\n",
    "    elif labels[i] == 'relief':\n",
    "        y.append(7)\n",
    "    elif labels[i] == 'fear':\n",
    "        y.append(8)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 9, dtype=\"float32\")\n",
    "del y\n",
    "\n",
    "\n",
    "def featureEngineering(tweet):\n",
    "    # Lower case tweet\n",
    "    tweetMod = tweet.lower()\n",
    "    # Replace URLs with a space in the message\n",
    "    tweetMod = re.sub('https?:\\/\\/[a-zA-Z0-9@:%._\\/+~#=?&;-]*', ' ', tweetMod)\n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    tweetMod = re.sub('\\$[a-zA-Z0-9]*', ' ', tweetMod)\n",
    "    # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
    "    tweetMod = re.sub('\\@[a-zA-Z0-9]*', ' ', tweetMod)\n",
    "    # Replace everything not a letter or apostrophe with a space\n",
    "    tweetMod = re.sub('[^a-zA-Z\\']', ' ', tweetMod)\n",
    "    # Remove single letter words\n",
    "    tweetMod = ' '.join([w for w in tweetMod.split() if len(w) > 1])\n",
    "\n",
    "    return tweetMod\n",
    "\n",
    "\n",
    "# Process for all tweets\n",
    "tweetData['modTweet'] = [featureEngineering(tweet) for tweet in tweetData['tweet']]\n",
    "\n",
    "def lemmatizeTweet(tweet):\n",
    "  words = [word for word in word_tokenize(tweet) if (word.isalpha()==1)]\n",
    "  # Remove stop words\n",
    "  stop = set(stopwords.words('english'))\n",
    "  words = [word for word in words if (word not in stop)]\n",
    "  # Lemmatize words (first noun, then verb)\n",
    "  wnl = nltk.stem.WordNetLemmatizer()\n",
    "  lemmatized = [wnl.lemmatize(wnl.lemmatize(word, 'n'), 'v') for word in words]\n",
    "  return \" \".join(lemmatized)\n",
    "\n",
    "tweetData['lemmatizedText'] = tweetData[\"modTweet\"].apply(lambda x:lemmatizeTweet(x))\n",
    "\n",
    "# Padding of sequences based on number of unique words\n",
    "tokenizer = Tokenizer(num_words=27608, split=' ')\n",
    "tokenizer.fit_on_texts(tweetData['lemmatizedText'].values)\n",
    "X = tokenizer.texts_to_sequences(tweetData['lemmatizedText'].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Epochs + Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:13:29.902545Z",
     "iopub.status.busy": "2021-11-12T03:13:29.901850Z",
     "iopub.status.idle": "2021-11-12T03:13:49.019579Z",
     "shell.execute_reply": "2021-11-12T03:13:49.018689Z",
     "shell.execute_reply.started": "2021-11-12T03:13:29.902505Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm():\n",
    "    keras.backend.clear_session()\n",
    "    model_dropout = Sequential()\n",
    "    model_dropout.add(Embedding(input_dim=128, output_dim=8, input_length=X.shape[1]))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "    model_dropout.add(Dense(9, activation='softmax'))\n",
    "    model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    return model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:13:49.021403Z",
     "iopub.status.busy": "2021-11-12T03:13:49.021150Z",
     "iopub.status.idle": "2021-11-12T03:13:50.566463Z",
     "shell.execute_reply": "2021-11-12T03:13:50.565741Z",
     "shell.execute_reply.started": "2021-11-12T03:13:49.021369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = KerasClassifier(build_fn=build_lstm, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "batch_size = [512, 256, 128, 64]\n",
    "epochs = [20, 50, 100, 200]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm():\n",
    "    keras.backend.clear_session()\n",
    "    model_dropout = Sequential()\n",
    "    model_dropout.add(Embedding(input_dim=128, output_dim=8, input_length=X.shape[1]))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "    model_dropout.add(Dense(9, activation='softmax'))\n",
    "    model_dropout.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "    return model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model=KerasClassifier(build_fn=build_lstm, epochs=50, batch_size=512, verbose=-1)\n",
    "\n",
    "# Define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:17:53.774395Z",
     "iopub.status.busy": "2021-11-12T03:17:53.773876Z",
     "iopub.status.idle": "2021-11-12T03:17:54.666405Z",
     "shell.execute_reply": "2021-11-12T03:17:54.665675Z",
     "shell.execute_reply.started": "2021-11-12T03:17:53.774356Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm():\n",
    "    keras.backend.clear_session()\n",
    "    model_dropout = Sequential()\n",
    "    model_dropout.add(Embedding(input_dim=128, output_dim=8, input_length=X.shape[1]))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "    model_dropout.add(Dense(9, activation='softmax'))\n",
    "    optimizer = Adam(lr = learn_rate)\n",
    "    model_dropout.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "    return model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:17:55.996309Z",
     "iopub.status.busy": "2021-11-12T03:17:55.995767Z",
     "iopub.status.idle": "2021-11-12T03:20:22.461589Z",
     "shell.execute_reply": "2021-11-12T03:20:22.460788Z",
     "shell.execute_reply.started": "2021-11-12T03:17:55.996269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model=KerasClassifier(build_fn=build_lstm, epochs=50, batch_size=512, verbose=-1)\n",
    "\n",
    "# Define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.03, 0.05, 0.07, 0.09, 0.1, 0.2]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm():\n",
    "    keras.backend.clear_session()\n",
    "    model_dropout = Sequential()\n",
    "    model_dropout.add(Embedding(input_dim=128, output_dim=8, input_length=X.shape[1]))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=256, return_sequences=True, kernel_initializer=init_mode)))\n",
    "    model_dropout.add(Dropout(0.4))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False, kernel_initializer=init_mode)))\n",
    "    model_dropout.add(Dense(9, activation='softmax'))\n",
    "    optimizer = Adam(lr = 0.001)\n",
    "    model_dropout.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "    return model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model=KerasClassifier(build_fn=build_lstm, epochs=50, batch_size=512, verbose=-1)\n",
    "\n",
    "# Define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(dropout_rate=0.0, weight_constraint=0):\n",
    "    embed_dim = 8\n",
    "    keras.backend.clear_session()\n",
    "    model_dropout = Sequential()\n",
    "    model_dropout.add(Embedding(input_dim=128, output_dim=embed_dim, input_length=X.shape[1]))\n",
    "    model_dropout.add(Dropout(dropout_rate))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=256, kernel_initializer='normal', return_sequences=True, kernel_constraint=maxnorm(weight_constraint))))\n",
    "    model_dropout.add(Dropout(dropout_rate))\n",
    "    model_dropout.add(Bidirectional(LSTM(units=128, kernel_initializer='normal', return_sequences=False)))\n",
    "    model_dropout.add(Dense(9, activation='softmax'))\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model_dropout.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "    return model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model=KerasClassifier(build_fn=build_lstm, epochs=50, batch_size=512, verbose=-1)\n",
    "\n",
    "# Define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial and Error of remaining parameters based on Accuracy + Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:20:57.997145Z",
     "iopub.status.busy": "2021-11-12T03:20:57.996874Z",
     "iopub.status.idle": "2021-11-12T03:20:58.850351Z",
     "shell.execute_reply": "2021-11-12T03:20:58.849597Z",
     "shell.execute_reply.started": "2021-11-12T03:20:57.997115Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(64,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:21:36.928553Z",
     "iopub.status.busy": "2021-11-12T03:21:36.927839Z",
     "iopub.status.idle": "2021-11-12T03:24:02.186810Z",
     "shell.execute_reply": "2021-11-12T03:24:02.186086Z",
     "shell.execute_reply.started": "2021-11-12T03:21:36.928512Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:24:02.189110Z",
     "iopub.status.busy": "2021-11-12T03:24:02.188733Z",
     "iopub.status.idle": "2021-11-12T03:24:02.460689Z",
     "shell.execute_reply": "2021-11-12T03:24:02.460039Z",
     "shell.execute_reply.started": "2021-11-12T03:24:02.189063Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the accuracies for the training epochs\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:24:02.462201Z",
     "iopub.status.busy": "2021-11-12T03:24:02.461852Z",
     "iopub.status.idle": "2021-11-12T03:24:02.734516Z",
     "shell.execute_reply": "2021-11-12T03:24:02.733827Z",
     "shell.execute_reply.started": "2021-11-12T03:24:02.462154Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the losses for the training epochs\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:25:39.804917Z",
     "iopub.status.busy": "2021-11-12T03:25:39.803946Z",
     "iopub.status.idle": "2021-11-12T03:25:41.355190Z",
     "shell.execute_reply": "2021-11-12T03:25:41.354340Z",
     "shell.execute_reply.started": "2021-11-12T03:25:39.804876Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(100,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:25:41.358736Z",
     "iopub.status.busy": "2021-11-12T03:25:41.358521Z",
     "iopub.status.idle": "2021-11-12T03:28:08.801441Z",
     "shell.execute_reply": "2021-11-12T03:28:08.800647Z",
     "shell.execute_reply.started": "2021-11-12T03:25:41.358710Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:28:08.803712Z",
     "iopub.status.busy": "2021-11-12T03:28:08.803399Z",
     "iopub.status.idle": "2021-11-12T03:28:09.103117Z",
     "shell.execute_reply": "2021-11-12T03:28:09.102207Z",
     "shell.execute_reply.started": "2021-11-12T03:28:08.803674Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the accuracies for the training epochs\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:28:09.105654Z",
     "iopub.status.busy": "2021-11-12T03:28:09.105251Z",
     "iopub.status.idle": "2021-11-12T03:28:09.424054Z",
     "shell.execute_reply": "2021-11-12T03:28:09.423281Z",
     "shell.execute_reply.started": "2021-11-12T03:28:09.105609Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the losses for the training epochs\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:28:54.377883Z",
     "iopub.status.busy": "2021-11-12T03:28:54.377313Z",
     "iopub.status.idle": "2021-11-12T03:28:55.228169Z",
     "shell.execute_reply": "2021-11-12T03:28:55.227464Z",
     "shell.execute_reply.started": "2021-11-12T03:28:54.377843Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(256,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:29:01.658648Z",
     "iopub.status.busy": "2021-11-12T03:29:01.657819Z",
     "iopub.status.idle": "2021-11-12T03:32:28.644286Z",
     "shell.execute_reply": "2021-11-12T03:32:28.643154Z",
     "shell.execute_reply.started": "2021-11-12T03:29:01.658595Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:32:28.646850Z",
     "iopub.status.busy": "2021-11-12T03:32:28.646563Z",
     "iopub.status.idle": "2021-11-12T03:32:29.080689Z",
     "shell.execute_reply": "2021-11-12T03:32:29.080053Z",
     "shell.execute_reply.started": "2021-11-12T03:32:28.646813Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:32:29.087130Z",
     "iopub.status.busy": "2021-11-12T03:32:29.084548Z",
     "iopub.status.idle": "2021-11-12T03:32:29.425072Z",
     "shell.execute_reply": "2021-11-12T03:32:29.424352Z",
     "shell.execute_reply.started": "2021-11-12T03:32:29.087090Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:33:42.395416Z",
     "iopub.status.busy": "2021-11-12T03:33:42.394581Z",
     "iopub.status.idle": "2021-11-12T03:33:43.251905Z",
     "shell.execute_reply": "2021-11-12T03:33:43.250234Z",
     "shell.execute_reply.started": "2021-11-12T03:33:42.395374Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(128,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:33:56.197972Z",
     "iopub.status.busy": "2021-11-12T03:33:56.197300Z",
     "iopub.status.idle": "2021-11-12T03:36:22.511183Z",
     "shell.execute_reply": "2021-11-12T03:36:22.510210Z",
     "shell.execute_reply.started": "2021-11-12T03:33:56.197928Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:36:22.515345Z",
     "iopub.status.busy": "2021-11-12T03:36:22.515117Z",
     "iopub.status.idle": "2021-11-12T03:36:22.818561Z",
     "shell.execute_reply": "2021-11-12T03:36:22.817849Z",
     "shell.execute_reply.started": "2021-11-12T03:36:22.515319Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:36:22.820579Z",
     "iopub.status.busy": "2021-11-12T03:36:22.820078Z",
     "iopub.status.idle": "2021-11-12T03:36:23.228802Z",
     "shell.execute_reply": "2021-11-12T03:36:23.228048Z",
     "shell.execute_reply.started": "2021-11-12T03:36:22.820539Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:36:51.876144Z",
     "iopub.status.busy": "2021-11-12T03:36:51.875331Z",
     "iopub.status.idle": "2021-11-12T03:36:52.716396Z",
     "shell.execute_reply": "2021-11-12T03:36:52.715669Z",
     "shell.execute_reply.started": "2021-11-12T03:36:51.876093Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(128,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:37:00.357385Z",
     "iopub.status.busy": "2021-11-12T03:37:00.356847Z",
     "iopub.status.idle": "2021-11-12T03:39:27.610778Z",
     "shell.execute_reply": "2021-11-12T03:39:27.610015Z",
     "shell.execute_reply.started": "2021-11-12T03:37:00.357346Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:39:27.613552Z",
     "iopub.status.busy": "2021-11-12T03:39:27.613258Z",
     "iopub.status.idle": "2021-11-12T03:39:28.017562Z",
     "shell.execute_reply": "2021-11-12T03:39:28.016694Z",
     "shell.execute_reply.started": "2021-11-12T03:39:27.613511Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:39:28.024426Z",
     "iopub.status.busy": "2021-11-12T03:39:28.022136Z",
     "iopub.status.idle": "2021-11-12T03:39:28.373672Z",
     "shell.execute_reply": "2021-11-12T03:39:28.373011Z",
     "shell.execute_reply.started": "2021-11-12T03:39:28.024384Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:40:05.684293Z",
     "iopub.status.busy": "2021-11-12T03:40:05.684019Z",
     "iopub.status.idle": "2021-11-12T03:40:06.568952Z",
     "shell.execute_reply": "2021-11-12T03:40:06.568209Z",
     "shell.execute_reply.started": "2021-11-12T03:40:05.684265Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 16\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(128,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:40:12.625061Z",
     "iopub.status.busy": "2021-11-12T03:40:12.624771Z",
     "iopub.status.idle": "2021-11-12T03:43:38.959196Z",
     "shell.execute_reply": "2021-11-12T03:43:38.958379Z",
     "shell.execute_reply.started": "2021-11-12T03:40:12.625015Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:43:38.961531Z",
     "iopub.status.busy": "2021-11-12T03:43:38.961187Z",
     "iopub.status.idle": "2021-11-12T03:43:39.239459Z",
     "shell.execute_reply": "2021-11-12T03:43:39.238772Z",
     "shell.execute_reply.started": "2021-11-12T03:43:38.961491Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:43:39.241362Z",
     "iopub.status.busy": "2021-11-12T03:43:39.240542Z",
     "iopub.status.idle": "2021-11-12T03:43:39.519266Z",
     "shell.execute_reply": "2021-11-12T03:43:39.518503Z",
     "shell.execute_reply.started": "2021-11-12T03:43:39.241322Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:44:22.498068Z",
     "iopub.status.busy": "2021-11-12T03:44:22.497507Z",
     "iopub.status.idle": "2021-11-12T03:44:23.374462Z",
     "shell.execute_reply": "2021-11-12T03:44:23.373672Z",
     "shell.execute_reply.started": "2021-11-12T03:44:22.498023Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 8\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(128,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:44:30.130065Z",
     "iopub.status.busy": "2021-11-12T03:44:30.129512Z",
     "iopub.status.idle": "2021-11-12T03:46:59.467776Z",
     "shell.execute_reply": "2021-11-12T03:46:59.467040Z",
     "shell.execute_reply.started": "2021-11-12T03:44:30.130022Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:46:59.474246Z",
     "iopub.status.busy": "2021-11-12T03:46:59.472271Z",
     "iopub.status.idle": "2021-11-12T03:46:59.832856Z",
     "shell.execute_reply": "2021-11-12T03:46:59.832223Z",
     "shell.execute_reply.started": "2021-11-12T03:46:59.474204Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:46:59.838584Z",
     "iopub.status.busy": "2021-11-12T03:46:59.836656Z",
     "iopub.status.idle": "2021-11-12T03:47:00.130370Z",
     "shell.execute_reply": "2021-11-12T03:47:00.129698Z",
     "shell.execute_reply.started": "2021-11-12T03:46:59.838545Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:49:16.300690Z",
     "iopub.status.busy": "2021-11-12T03:49:16.299961Z",
     "iopub.status.idle": "2021-11-12T03:49:17.538231Z",
     "shell.execute_reply": "2021-11-12T03:49:17.537516Z",
     "shell.execute_reply.started": "2021-11-12T03:49:16.300646Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 8\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(128,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:49:39.357223Z",
     "iopub.status.busy": "2021-11-12T03:49:39.356660Z",
     "iopub.status.idle": "2021-11-12T03:53:05.002647Z",
     "shell.execute_reply": "2021-11-12T03:53:05.001908Z",
     "shell.execute_reply.started": "2021-11-12T03:49:39.357186Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:53:05.004838Z",
     "iopub.status.busy": "2021-11-12T03:53:05.004492Z",
     "iopub.status.idle": "2021-11-12T03:53:05.284598Z",
     "shell.execute_reply": "2021-11-12T03:53:05.283924Z",
     "shell.execute_reply.started": "2021-11-12T03:53:05.004796Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:53:05.286310Z",
     "iopub.status.busy": "2021-11-12T03:53:05.285876Z",
     "iopub.status.idle": "2021-11-12T03:53:05.575592Z",
     "shell.execute_reply": "2021-11-12T03:53:05.574779Z",
     "shell.execute_reply.started": "2021-11-12T03:53:05.286269Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:54:43.436061Z",
     "iopub.status.busy": "2021-11-12T03:54:43.435281Z",
     "iopub.status.idle": "2021-11-12T03:54:44.367732Z",
     "shell.execute_reply": "2021-11-12T03:54:44.366078Z",
     "shell.execute_reply.started": "2021-11-12T03:54:43.436013Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 8\n",
    "keras.backend.clear_session()\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Embedding(128,embed_dim,input_length = X.shape[1]))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
    "model_dropout.add(Dropout(rate=0.4))\n",
    "model_dropout.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "model_dropout.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:54:52.715182Z",
     "iopub.status.busy": "2021-11-12T03:54:52.714615Z",
     "iopub.status.idle": "2021-11-12T03:57:35.514982Z",
     "shell.execute_reply": "2021-11-12T03:57:35.514243Z",
     "shell.execute_reply.started": "2021-11-12T03:54:52.715123Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dropout.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model_dropout.fit(X_train, Y_train, epochs = 20, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:57:35.517264Z",
     "iopub.status.busy": "2021-11-12T03:57:35.516973Z",
     "iopub.status.idle": "2021-11-12T03:57:35.797673Z",
     "shell.execute_reply": "2021-11-12T03:57:35.796892Z",
     "shell.execute_reply.started": "2021-11-12T03:57:35.517227Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testAcc9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:57:35.800205Z",
     "iopub.status.busy": "2021-11-12T03:57:35.798907Z",
     "iopub.status.idle": "2021-11-12T03:57:36.093914Z",
     "shell.execute_reply": "2021-11-12T03:57:36.093181Z",
     "shell.execute_reply.started": "2021-11-12T03:57:35.800150Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('cross-entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('testloss9.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
